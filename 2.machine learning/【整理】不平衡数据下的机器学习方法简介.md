# 【整理】不平衡数据下的机器学习方法简介

[原文地址](http://www.jianshu.com/p/3e8b9f2764c8)

> 不平衡数据的场景也出现在互联网应用的方方面面，如搜索引擎的点击预测（点击的网页往往占据很小的比例），电子商务领域的商品推荐（推荐的商品被购买的比例很低），信用卡欺诈检测，网络攻击识别等等。

[TOC]

### 一.定义及存在问题
* **定义**：顾名思义，即我们的数据集样本类别极不均衡，以二分类问题为例，假设我们的数据集是$S$，数据集中的多数类为$S_maj$，少数类为$S_min$，通常情况下把多数类样本的比例为$100:1$,$1000:1$，甚至$10000:1$这种情况下为不平衡数据。
* **导致的问题**：传统的学习方法以降低总体分类精度为目标，将所有样本一视同仁，同等对待，如下图1所示，造成了分类器在多数类的分类精度较高而在少数类的分类精度很低。机器学习模型都有一个待优化的损失函数，以我们最常用最简单的二元分类器逻辑回归为例，其损失函数如下公式1所示，逻辑回归以优化总体的精度为目标，不同类别的误分类情况产生的误差是相同的，考虑一个$500:1$的数据集，即使把所有样本都预测为多数类其精度也能达到$500/501$之高，很显然这并不是一个很好的学习效果，因此传统的学习算法在不平衡数据集中具有较大的局限性。

![](https://github.com/31462019/workspace/blob/master/2.machine%20learning/img/bph_1.png)

图1 传统学习在不平衡数据下的缺点
![](https://github.com/31462019/workspace/blob/master/2.machine%20learning/img/bph_2.png)
公式1 逻辑回归的交叉熵损失函数
### 二.不平衡学习的方法
解决方法主要有两个方面：
1. 从**数据**角度出发，主要方法为抽样，从而让样本相对均衡
2. 从**算法**的角度出发，考虑不同五分类情况代价的差异性对算法进行优化，使得我们的算法在不平衡数据下也能有较好的效果。
#### 1.数据层面-采样
采样算法通过某一种策略改变样本的类别分布，以达到将不平衡分布的样本转化为相对平衡分布的样本的目的。
##### a.随机采样
* __采样过程__：
随机采样主要分为两种类型，分别为**随机欠采样**(<font color=red>多数类样本</font>)和**随机过采样**(<font color=red>少数类样本</font>)两种。
随机欠采样有两种类型分别为有放回和无放回两种，无放回欠采样在对多数类某样本被采样后不会再被重复采样，有放回采样则有可能。随机欠采样顾名思义即从多数类$S_maj$中随机选择少量样本$E$再合并原有少数类样本作为新的训练数据集，新数据集为$S_min+E$。
随机过采样则正好相反，即通过多次有放回随机采样从少数类$S_min$中抽取数据集$E$，采样的数量要大于原有少数类的数量，最终的训练集为$S_maj+E$。
* __随机采样存在问题__：
a. 对于随机欠采样，由于采样的样本要少于原样本集合，因此会造成一些**信息缺失**，未被采样的样本往往带有__很重要的信息__。
b. 对于随机过采样，由于需要对少数类样本进行复制因此扩大了数据集，造成**模型训练复杂度加大**，另一方面也容易造成模型的**过拟合**问题。
##### b.SMOTE算法(<font color=red>解决随机过采样容易过拟合问题</font>)
SMOTE全称是Synthetic Minority Oversampling Technique即合成少数类过采样技术，它是基于随机过采样算法的一种改进方案，由于随机过采样采取简单复制样本的策略来增加少数类样本，这样容易产生模型过拟合的问题，即使得模型学习到的信息过于特别(Specific)而不够泛化(General)，SMOTE算法的基本思想是对少数类样本进行分析并根据少数类样本人工合成新样本添加到数据集中，具体如图2所示，算法流程如下。
* 对于少数类中每一个样本$x$，以欧氏距离为标准计算它到少数类样本集$S_min$中所有样本的距离，得到其k近邻。
* 根据样本不平衡比例设置一个采样比例以确定采样倍率$N$，对于每一个少数类样本$x$，从其k近邻中随机选择若干个样本，假设选择的近邻为$\hat{x}$。
* 对于每一个随机选出的近邻$\hat{x}$，分别与原样本按照如下的公式构建新的样本。

![](https://github.com/31462019/workspace/blob/master/2.machine%20learning/img/bph_3.png)

图2 SMOTE算法
实践证明此方法可以提高分类器的性能。但是由于对每个少数类样本都生成新样本，因此容易发生生成**样本重叠**(Overlapping)的问题，为了解决SMOTE算法的这一缺点提出一些改进算法，其中的一种是Borderline-SMOTE算法，如图3所示。
在Borderline-SMOTE中，若少数类样本的每个样本$x_i$求k近邻，记作$S_i-knn$，且$S_i-knn$属于整个样本集合$S$而不再是少数类样本(<font color=red>即包括多数类的样本</font>)，若满足
![](https://github.com/31462019/workspace/blob/master/2.machine%20learning/img/bph_4.png)

则将样本$x_i$加入DANGER集合，显然DANGER集合代表了接近分类边界的样本，将DANGER当作SMOTE种子样本的输入生成新样本。特别地，当上述条件取右边界，即k近邻中全部样本都是多数类时，此样本不会被选择为种样本生成新样本，此情况下的样本为噪音。
![](https://github.com/31462019/workspace/blob/master/2.machine%20learning/img/bph_5.png)
图3 Borderline-SMOTE算法
##### c.Informed Undersamping
informed undersampling采样技术主要有两种方法分别是EasyEnsemble算法和BalanceCascade算法。
###### (1)EasyEnsemble
 **EasyEnsemble**算法如下图4所示，此算法类似于随机森林的Bagging方法，它把数据划分为两部分，分别是多数类样本和少数类样本，对于多数类样本$S_maj$，通过n次有放回抽样生成n份子集，少数类样本分别和这n份样本合并训练一个模型，这样可以得到n个模型，最终的模型是这n个模型预测结果的平均值(<font color=red>最后预测的时候，是使用之前学习到的所有adaboost中的弱分类器（就是每颗决策树）的预测结果向量（每个树给的结果组成一个向量）和对应的权重向量做内积，然后减去阈值，根据差的符号确定样本的类别。</font>)。
matlab实现
![](https://github.com/31462019/workspace/blob/master/2.machine%20learning/img/bph_6.png)
图4 EasyEsemble算法
###### (2)BalanceCascade
* **BalanceCascade**算法是一种级联算法，BalanceCascade从多数类$S_maj$中有效地选择N且满足$\mid N\mid=\mid S_min\mid$，将N和$\ S_min$合并为新的数据集进行训练，新训练集对每个多数类样本$x_i$进行预测若预测对则$S_maj=S_maj-x_i$(<font color=red>如果预测正确则说明当前模型对该样本有分类能力，继续对分不出的样本训练模型，最后是模型的组合</font>)。依次迭代直到满足某一停止条件，最终的模型是多次迭代模型的组合。
 
#### 2.算法层面-代价敏感学习
采样算法从数据层面解决不平衡数据的学习问题，在算法层面上解决不平衡数据学习的方法主要是基于代价敏感学习算法(Cost-Sensitive Learning)，代价敏感学习方法的核心要素是代价矩阵。
##### 代价矩阵
我们注意到在实际的应用中不同类型的误分类情况导致的代价是不一样的，例如在医疗中，“将病人误疹为健康人”和“将健康人误疹为病人”的代价不同；在信用卡盗用检测中，“将盗用误认为正常使用”与“将正常使用识破认为盗用”的代价也不相同，因此我们定义代价矩阵如下图5所示。标记$C_ij$为将类别j误分类为类别i的代价，显然$C_00=C_11=0$，$C_01,C_10$为两种不同的误分类代价，当两者相等时为代价不敏感的学习问题。
![](https://github.com/31462019/workspace/blob/master/2.machine%20learning/img/bph_7.png)
图5 代价矩阵
##### 代价敏感学习算法
基于以上代价矩阵的分析，代价敏感学习方法主要有以下三种实现方式，分别是：
1. 从学习模型出发，着眼于对某一具体学习方法的改造，使之能适应不平衡数据下的学习，研究者们针对不同的学习模型如感知机，支持向量机，决策树，神经网络等分别提出了其代价敏感的版本。以代价敏感的决策树为例，可从三个方面对其进行改进以适应不平衡数据的学习，这三个方面分别是决策阈值的选择方面、分裂标准的选择方面、剪枝方面，这三个方面中都可以将代价矩阵引入，具体实现算法可参考参考文献中的相关文章。
2. 从贝叶斯风险理论出发，把代价敏感学习看成是分类结果的一种后处理，按照传统方法学习到一个模型，以实现损失最小为目标对结果进行调整，优化公式如下所示。此方法的优点在于它可以不依赖所用具体的分类器，但是缺点也很明显它要求分类器输出值为概率。
![](https://github.com/31462019/workspace/blob/master/2.machine%20learning/img/bph_8.png)
3. 从预处理的角度出发，将代价用于权重的调整，使得分类器满足代价敏感的特性，下面讲解一种基于Adaboost的权重更新策略。
##### 举例：AdaCost 算法
让我们先来简单回顾一下Adaboost算法，如下图6所示。Adaboost算法通过反复迭代，每一轮迭代学习到一个分类器，并根据当前分类器的表现更新样本的权重，如图中红框所示，其更新策略为正确分类样本权重降低，错误分类样本权重加大，最终的模型是多次迭代模型的一个加权线性组合，分类越准确的分类器将会获得越大的权重。
![](https://github.com/31462019/workspace/blob/master/2.machine%20learning/img/bph_9.png)
图6 Adaboost算法

AdaCost算法修改了Adaboost算法的权重更新策略，其基本思想是对于代价高的误分类样本大大地提高其权重，而对于代价高的正确分类样本适当地降低其权重，使其权重降低相对较小。总体思想是代价高样本权重增加得大降低得慢。其样本权重按照如下公式进行更新。其中$\beta_+$和$\beta_-$分别表示样本被正确和错误分类情况下$\beta$的取值。
![](https://github.com/31462019/workspace/blob/master/2.machine%20learning/img/bph_10.png)

### 三.不平衡学习的评价方法
####正确率和F值
正确率和F值的计算都是基于混淆矩阵(Confusion Matrix)的，混淆矩阵如下图7所示，每行代表预测情况，每列代表实际类别，TP,FP,FN,TN分别代表正类正确分类数量，预测为正类但是真实为负类，预测为负类但是真实为正类，负类正确分类数量。
![](https://github.com/31462019/workspace/blob/master/2.machine%20learning/img/bph_11.png)
图7 混淆矩阵

正确率(Accuracy)和F值的计算如下式所示。可见正确率或错误率并不能表示不平衡数据下模型的表现，对于不平衡数据即使全部预测为多数类也可以达到较高的正确率较低的错误率，而F值同时考虑到了少数类的准确率和召回率，因此能衡量不平衡数据下模型的表现，其中$\beta$取值通常为1。

![](https://github.com/31462019/workspace/blob/master/2.machine%20learning/img/bph_12.png)
#### G-Mean
G-Mean是另外一个指标，也能评价不平衡数据的模型表现，其计算公式如下。

![](https://github.com/31462019/workspace/blob/master/2.machine%20learning/img/bph_13.png)
#### ROC曲线和AUC
为了介绍ROC曲线首先引入两个是，分别是FP_rate和TP_rate，它们分别表示1-负类召回率和正类召回率，显然模型表示最好的时候FP_rate=0且TP_rate=1，我们以FP_rate为横坐标，TP_rate为纵坐标可以得到点(FP_rate,TP_rate)，通过调整模型预测的阈值可以得到不同的点，将这些点可以连成一条曲线，这条曲线叫做接受者工作特征曲线(Receiver Operating Characteristic Curve，简称ROC曲线）如下图8所示。显然A点为最优点，ROC曲线越靠近A点代表模型表现越好，曲线下面积（Area Under Curve, AUC）越大，AUC是衡量模型表现好坏的一个重要指标。
![](https://github.com/31462019/workspace/blob/master/2.machine%20learning/img/bph_14.png)
图8 ROC曲线

### 总结
本文介绍了不平衡数据下学习的常用方法及其评价指标，方法主要从数据和模型两个层面考虑，数据方面的方法主要为采样算法，模型方面主要基于代价敏感学习。本文主要来源于论文“Learning from Imbalanced Data”。(<font color=red>对于模型或者算法的描述稍显简略，没讲的太清楚，前面采样算法介绍的很详细</font>)


文／练绪宝（简书作者）
原文链接：http://www.jianshu.com/p/3e8b9f2764c8
